{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 比赛背景\n",
    "\n",
    "第三届中国AI+创新创业大赛由中国人工智能学会主办，半监督学习目标定位竞赛分赛道要求选手基于少量有标注数据训练模型，使分类网络具有目标定位能力，实现半监督目标定位任务。\n",
    "\n",
    "中国人工智能学会（Chinese Association for Artificial Intelligence，CAAI）成立于1981年，是经国家民政部正式注册的我国智能科学技术领域唯一的国家级学会，是全国性4A级社会组织，挂靠单位为北京邮电大学；是中国科学技术协会的正式团体会员，具有推荐“两院院士”的资格。\n",
    "\n",
    "中国人工智能学会目前拥有51个分支机构，包括43个专业委员会和8个工作委员会，覆盖了智能科学与技术领域。学会活动的学术领域是智能科学技术，活动地域是中华人民共和国全境，基本任务是团结全国智能科学技术工作者和积极分子通过学术研究、国内外学术交流、科学普及、学术教育、科技会展、学术出版、人才推荐、学术评价、学术咨询、技术评审与奖励等活动促进我国智能科学技术的发展，为国家的经济发展、社会进步、文明提升、安全保障提供智能化的科学技术服务。\n",
    "\n",
    "中国“AI+”创新创业大赛由中国人工智能学会发起主办，是为了配合实施创新驱动助力工程，深入开展服务企业技术创新活动，进一步提高我国文化建设和实践创新能力，展示智能科学与技术等相关学科建设的新经验、新成果，促进专业内涵的建设而发起的综合性大赛平台。\n",
    "\n",
    "飞桨PaddlePaddle作为中国首个自主研发、功能完备、开源开放的产业级深度学习平台，为本次比赛的参赛选手提供了集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体的一站式服务。百度大脑AI Studio作为官方指定且唯一的竞赛日常训练平台，为参赛选手提供高效的学习和开发环境，更有亿元Tesla V100算力免费赠送，助力选手取得优异成绩。\n",
    "\n",
    "[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 简要介绍\n",
    "## 赛题背景\n",
    "半监督学习(Semi-Supervised Learning)是指通过大量无标记数据和少量有标记数据完成模型训练，解决具有挑战性的模式识别任务。近几年，随着计算硬件性能的提升和大量大规模标注数据集的开源，基于深度卷积神经网络(Deep Convolutional Neural Networks, DCNNs)的监督学习研究取得了革命性进步。然而，监督学习模型的优异性能要以大量标注数据作为支撑，可现实中获得数量可观的标注数据十分耗费人力物力(例如，获取像素级标注数据)。于是， 半监督学习逐渐成为深度学习领域的热门研究方向，只需要少量标记数据就可以完成模型训练过程，更适用于现实场景中的各种任务。\n",
    "## 比赛任务\n",
    "本次比赛要求选手基于少量有标签的数据训练模型，使分类网络具有目标定位能力，实现半监督目标定位任务。每- -位参赛选手仅可以使用ImageNet大型视觉识别竞赛(LSVRC)的训练集图像作为训练数据，其中有标签的训练数据仅可以使用大赛组委会提供的像素级标注。\n",
    "## 数据集介绍\n",
    "* 训练数据集包括50,000幅像素级标注的图像，共包含500个类，每个类100幅图像;\n",
    "* A榜测试数据集包括1 1,878幅无标注的图像;\n",
    "* B榜测试数据集包括10,989幅无标注的图像。\n",
    "## 评价指标\n",
    "本次比赛使用loU曲线作为评价指标，即利用预测的目标的定位概率图，计算不同阈值下预测结果与真实目标之间的IoU分数，最后取一个最高点作为最终的分数。在理想状态下，loU曲线最高值接近1.0,对应的阈值为255,因为阈值越高，目标对象与背景的对比度越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型介绍\n",
    "\n",
    "尝试了Unet deeplabv3 deeplabv3P 三个模型 其中deeplabv3P效果最好 \n",
    "\n",
    "因为笔者刚接触语义分割还不会使用paddlepaddle进行模型融合 所以得分为0.76449 再调整参数得分提高也有限 \n",
    "\n",
    "在调参过程中 主要针对learning_rate iters batch_size 进行尝试 后来发现在iters大于25000时提高就不明显"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 提高策略\n",
    "模型融合 集成学习 是一个很好的提高策略 \n",
    "\n",
    "经过实验发现单个的模型 提高分数很有限\n",
    "\n",
    "奈何笔者刚接触语义分割，不知如何使用Paddlepaddle进行模型融合 以后zaijiezli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 参数介绍\n",
    "\n",
    "```\n",
    "batch_size: 16\n",
    "iters: 40000\n",
    "\n",
    "train_dataset:\n",
    "  type: Dataset\n",
    "  dataset_root: /home/aistudio\n",
    "  train_path: /home/aistudio/train.txt\n",
    "  num_classes: 2\n",
    "  transforms:\n",
    "    - type: RandomHorizontalFlip\n",
    "    - type: RandomVerticalFlip\n",
    "    - type: RandomDistort\n",
    "      brightness_range: 0.4\n",
    "      contrast_range: 0.4\n",
    "      saturation_range: 0.4\n",
    "    - type: Resize\n",
    "      target_size: [256, 256]\n",
    "    - type: Normalize\n",
    "  mode: train\n",
    "\n",
    "val_dataset:\n",
    "  type: Dataset\n",
    "  dataset_root: /home/aistudio\n",
    "  val_path: /home/aistudio/val.txt\n",
    "  num_classes: 2\n",
    "  transforms:\n",
    "    - type: Resize\n",
    "      target_size: [256, 256]\n",
    "    - type: Normalize\n",
    "  mode: val\n",
    "\n",
    "model:\n",
    "  type: DeepLabV3P\n",
    "  backbone:\n",
    "    type: ResNet50_vd\n",
    "    output_stride: 8\n",
    "    multi_grid: [1, 2, 4]\n",
    "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
    "  backbone_indices: [0, 3]\n",
    "  aspp_ratios: [1, 12, 24, 36]\n",
    "  aspp_out_channels: 256\n",
    "  align_corners: False\n",
    "  pretrained: null\n",
    "\n",
    "optimizer:\n",
    "  type: sgd\n",
    "  momentum: 0.9\n",
    "  weight_decay: 4.0e-5\n",
    "\n",
    "lr_scheduler:\n",
    "  type: PolynomialDecay\n",
    "  learning_rate: 0.005\n",
    "  end_lr: 0\n",
    "  power: 0.9\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: MixedLoss\n",
    "      losses:\n",
    "        - type: CrossEntropyLoss\n",
    "        #- type: LovaszSoftmaxLoss\n",
    "        #- type: DiceLoss\n",
    "      coef: [1.0]\n",
    "  coef: [1]\n",
    "\n",
    "```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/data/data103518/PaddleSeg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /home/aistudio/PaddleSeg.zip, /home/aistudio/PaddleSeg.zip.zip or /home/aistudio/PaddleSeg.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "#解压一下略小改之后的PaddleSeg，解压一次就可以注释掉了\r\n",
    "!unzip -oq /home/aistudio/PaddleSeg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压数据集至data/目录\r\n",
    "!unzip -qo data/data95249/train_50k_mask.zip -d data/\r\n",
    "!unzip -oq data/data95249/第一阶段test.zip -d data/\r\n",
    "!unzip -oq data/data95249/train_image.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压B榜数据集到指定目录\r\n",
    "!unzip -oq /home/aistudio/data/data100087/B榜测试数据集.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import sys\r\n",
    "sys.path.append(\"PaddleSeg\")\r\n",
    "import paddleseg\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "from tqdm import tqdm\r\n",
    "import random\r\n",
    "#设置随机数种子\r\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_txt(file_name, imgs_path, labels_path=None, mode='train', val_pro=0.2):\r\n",
    "    assert mode==\"train\" or mode==\"test\", \"ERROR:mode must be train or test.\"\r\n",
    "    if mode!=\"test\":\r\n",
    "        train_path = []\r\n",
    "        for idx, f_path in enumerate(imgs_path):\r\n",
    "            for i_path in sorted(os.listdir(f_path)):\r\n",
    "                path1 = os.path.join(f_path, i_path) \r\n",
    "                path2 = os.path.join(labels_path[idx], i_path)\r\n",
    "                train_path.append((path1, path2, str(idx)))\r\n",
    "        \r\n",
    "        if val_pro>=0 and val_pro<=1:\r\n",
    "            #打乱数据\r\n",
    "            random.shuffle(train_path)\r\n",
    "            val_len = int(len(train_path)*val_pro)\r\n",
    "            val_path = train_path[:val_len]\r\n",
    "            train_path = train_path[val_len:]\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")\r\n",
    "            with open(file_name[1], 'w') as f:\r\n",
    "                for path in val_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")  \r\n",
    "            return len(train_path), val_len\r\n",
    "        else:\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\") \r\n",
    "            return len(train_path), 0\r\n",
    "    else:\r\n",
    "        with open(file_name, 'w') as f:\r\n",
    "            for path in imgs_path:\r\n",
    "                img_path = os.path.join(test_path, path)\r\n",
    "                f.write(img_path+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_txt(data_root, train_imgs_dir=None, train_labels_dir=None, test_dir=None, val_pro=0.2):\r\n",
    "    if train_imgs_dir is not None:\r\n",
    "        if os.path.exists(\"train.txt\"):\r\n",
    "            os.remove(\"train.txt\")\r\n",
    "        if os.path.exists(\"val.txt\"):\r\n",
    "            os.remove(\"val.txt\")\r\n",
    "        train_imgs_dir = os.path.join(data_root, train_imgs_dir)\r\n",
    "        train_labels_dir = os.path.join(data_root, train_labels_dir)\r\n",
    "        file_names = os.listdir(train_imgs_dir)\r\n",
    "        file_names = sorted(file_names)\r\n",
    "        train_imgs_path, train_labels_path =[], []\r\n",
    "        for na in file_names:\r\n",
    "            train_imgs_path.append(os.path.join(train_imgs_dir, na))\r\n",
    "            train_labels_path.append(os.path.join(train_labels_dir, na))\r\n",
    "        train_len, val_len = write_txt([\"train.txt\", \"val.txt\"], train_imgs_path, train_labels_path, mode='train', val_pro=val_pro)\r\n",
    "        \r\n",
    "        print(\"训练数据整理完毕！训练集长度：{}，验证集长度：{}， 类别数：{}\".format(train_len, val_len, len(file_names)))\r\n",
    "\r\n",
    "    if test_dir is not None:\r\n",
    "        if os.path.exists(\"test.txt\"):\r\n",
    "            os.remove(\"test.txt\")\r\n",
    "        global test_path\r\n",
    "        test_path = os.path.join(data_root, test_dir)\r\n",
    "        test_imgs_path_list = sorted(os.listdir(test_path))\r\n",
    "        write_txt(\"test.txt\", test_imgs_path_list, mode=\"test\")\r\n",
    "        print(\"测试数据整理完毕！测试集长度：{}\".format(len(test_imgs_path_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_txt_2(data_root,  test_dir=None):\r\n",
    "    if test_dir is not None:\r\n",
    "        if os.path.exists(\"val.txt\"):\r\n",
    "            os.remove(\"val.txt\")\r\n",
    "        global test_path\r\n",
    "        test_path = os.path.join(data_root, test_dir)\r\n",
    "        test_imgs_path_list = sorted(os.listdir(test_path))\r\n",
    "        write_txt(\"test2.txt\", test_imgs_path_list, mode=\"test\")\r\n",
    "        print(\"测试数据二整理完毕！测试集长度：{}\".format(len(test_imgs_path_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据整理完毕！训练集长度：40000，验证集长度：10000， 类别数：500\n",
      "测试数据整理完毕！测试集长度：11878\n"
     ]
    }
   ],
   "source": [
    "data_root = \"data\"\r\n",
    "train_imgs_dir = \"train_image\"\r\n",
    "train_labels_dir = \"train_50k_mask\"\r\n",
    "test_dir = \"val_image\"\r\n",
    "create_txt(data_root, train_imgs_dir, train_labels_dir, test_dir, val_pro=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据二整理完毕！测试集长度：10989\n"
     ]
    }
   ],
   "source": [
    "data_root = \"data\"\r\n",
    "test_dir = \"test_image\"\r\n",
    "create_txt_2(data_root, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 参数配置及训练\n",
    "在deeplabv3P-2.yml中修改参数配置，重启后直接运行下一行代码训练及验证\n",
    "\n",
    "训练好的模型存储在output_deeplabv3_2 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2021-08-08 22:33:44 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-166-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: False\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-08-08 22:33:44 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 16\n",
      "iters: 40000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 1.0\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.005\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: false\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "    type: ResNet50_vd\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  pretrained: null\n",
      "  type: DeepLabV3P\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: /home/aistudio/train.txt\n",
      "  transforms:\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val.txt\n",
      "------------------------------------------------\n",
      "2021-08-08 22:33:45 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "Connecting to https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "Downloading resnet50_vd_ssld_v2.tar.gz\n",
      "[==================================================] 100.00%\n",
      "Uncompress resnet50_vd_ssld_v2.tar.gz\n",
      "[==================================================] 100.00%\n",
      "2021-08-08 22:33:56 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"PaddleSeg/train.py\", line 190, in <module>\n",
      "    main(args)\n",
      "  File \"PaddleSeg/train.py\", line 185, in main\n",
      "    fp16=args.fp16)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/train.py\", line 180, in train\n",
      "    logits_list = model(images)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/deeplab.py\", line 83, in forward\n",
      "    logit_list = self.head(feat_list)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/deeplab.py\", line 152, in forward\n",
      "    x = self.aspp(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/layers/pyramid_pool.py\", line 97, in forward\n",
      "    y = block(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/layers/layer_libs.py\", line 124, in forward\n",
      "    x = self.depthwise_conv(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/layers/layer_libs.py\", line 74, in forward\n",
      "    x = self._conv(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/conv.py\", line 667, in forward\n",
      "    use_cudnn=self._use_cudnn)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/conv.py\", line 114, in _conv_nd\n",
      "    pre_bias = getattr(core.ops, op_type)(x, weight, *attrs)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python PaddleSeg/train.py --config deeplabv3P-2.yml --do_eval  --use_vdl --save_dir /home/aistudio/output_deeplabv3_1/ --save_interval 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 推理\n",
    "已在PaddleSeg中做了修改可以直接预测出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2021-08-08 22:34:19 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 16\n",
      "iters: 40000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 1.0\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.005\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: false\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "    type: ResNet50_vd\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  pretrained: null\n",
      "  type: DeepLabV3P\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: /home/aistudio/train.txt\n",
      "  transforms:\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val.txt\n",
      "------------------------------------------------\n",
      "2021-08-08 22:34:20 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "2021-08-08 22:34:21 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "2021-08-08 22:34:21 [INFO]\tNumber of predict images = 10989\n",
      "2021-08-08 22:34:21 [INFO]\tLoading pretrained model from output_deeplabv3_2/best_model/model.pdparams\n",
      "2021-08-08 22:34:25 [INFO]\tThere are 360/360 variables loaded into DeepLabV3P.\n",
      "2021-08-08 22:34:25 [INFO]\tStart to predict...\n",
      "   10/10989 [..............................] - ETA: 3:04:1^C\n",
      "Traceback (most recent call last):\n",
      "  File \"PaddleSeg/predict.py\", line 202, in <module>\n",
      "    main(args)\n",
      "  File \"PaddleSeg/predict.py\", line 197, in main\n",
      "    **test_config)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/predict.py\", line 115, in predict\n",
      "    crop_size=crop_size)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/infer.py\", line 218, in inference\n",
      "    logits = model(im)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/deeplab.py\", line 82, in forward\n",
      "    feat_list = self.backbone(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/resnet_vd.py\", line 351, in forward\n",
      "    y = block(y)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/resnet_vd.py\", line 130, in forward\n",
      "    data_format=self.data_format)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/common.py\", line 1320, in pad\n",
      "    \"data_format\", data_format, \"name\", name)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#推理\r\n",
    "!python PaddleSeg/predict.py --config deeplabv3P-2.yml --model_path output_deeplabv3_2/best_model/model.pdparams --image_path data/test_image  --save_dir output #--aug_pred --flip_horizontal --flip_vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 压缩结果，提交文件\n",
    "[第三届中国AI+创新创业大赛：半监督学习目标定位竞赛](https://aistudio.baidu.com/aistudio/competition/detail/78)\n",
    "\n",
    "最终得分 0.76449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd output/result_1/results\r\n",
    "!zip -r -oq /home/aistudio/pred.zip ./\r\n",
    "%cd /home/aistudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 改进方向\n",
    "* 使用模型融合 经过实验 单个的模型提高的分数有限，而对比高分方案 模型融合是一个很大的提分点\n",
    "* 试试其他模型架构，或进一步自己改进\n",
    "* 试用一下其他数据增强操作\n",
    "* 调参\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
